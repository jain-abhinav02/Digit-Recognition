# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ORSqqzJSnAgb4REjzUwUIvN2UmFnILmQ
"""

from keras.datasets import mnist
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
import numpy as np
from keras.layers import Dense
from keras.models import Sequential
from keras import utils as np_utils

(x_train,y_train),(x_test,y_test)=mnist.load_data()

x_train=x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]).astype('float32')
x_test=x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]).astype('float32')
x_train=x_train/255
x_test=x_test/255

y_train=np_utils.to_categorical(y_train,10)
y_test=np_utils.to_categorical(y_test,10)

model=Sequential()
model.add(Dense(units=784,input_dim=784,activation='relu'))
#model.add(Dense(units=100,activation='relu'))
#model.add(Dense(units=16,activation='relu'))
model.add(Dense(units=10,activation='softmax'))

model.summary()

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
model.fit(x_train,y_train,batch_size=128,epochs=20)

loss,accuracy =model.evaluate(x_test,y_test,verbose=False)

print(loss)
print(accuracy)